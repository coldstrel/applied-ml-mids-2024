{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6XZ55wHbdm5"
      },
      "source": [
        "# Part 1 of the Machine Learning Project\n",
        "\n",
        "## Preliminaries\n",
        "\n",
        "\n",
        "Before satring familiarize yourself with pandas reading the “10 minutes to pandas” tutorial: https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
        "\n",
        "Browse through the full pandas user guide when needed: https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html\n",
        "\n",
        "\n",
        "## Load libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94VoIo4Gwhnc"
      },
      "source": [
        "Test on Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L8jsxX6eaxL_"
      },
      "outputs": [],
      "source": [
        "# numpy and pandas for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# File system manangement\n",
        "import os\n",
        "\n",
        "# Suppress warnings\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "# matplotlib and seaborn for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctTp1HonbYpj"
      },
      "source": [
        "<p><img alt=\"Datasets\" src=\"https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "\n",
        "<h1>Datasets</h1>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dQVEExt5zBTK",
        "outputId": "2dcd340a-1df2-471a-fa70-27a3fd7fb2cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TAo_jy0PhBEY"
      },
      "outputs": [],
      "source": [
        "## Change this part with your own dataset files\n",
        "previous_application = 'drive/MyDrive/Advanced_Machine_Learning/previous_application.csv'\n",
        "src_bureau = 'drive/MyDrive/Advanced_Machine_Learning/bureau.csv'\n",
        "src_bureau_balance = 'drive/MyDrive/Advanced_Machine_Learning/bureau_balance.csv'\n",
        "src_train = 'drive/MyDrive/Advanced_Machine_Learning/application_train.csv'\n",
        "src_test = 'drive/MyDrive/Advanced_Machine_Learning/application_test.csv'\n",
        "\n",
        "\n",
        "# If you cannot load the directly the csv from Google drive (Google restrictions), download them manually then change the path to load them locally\n",
        "\n",
        "app_train = pd.read_csv(src_train)\n",
        "app_test = pd.read_csv(src_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPBTWB1ViFHe"
      },
      "source": [
        "<h1>Loading the datasets (2 pts)</h1>\n",
        "\n",
        "1. Similarly to the train set, load the test set, the bureau dataset and the past applications dataset.\n",
        "\n",
        "2. Display for each the number of rows and the number of columns\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 1: Correct approach + code: 1pt\n",
        "* 2: Code: 1pts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GjoGTJvLiBPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f503ea9-434b-4445-d4d3-e45ca53566ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows and columns for previous application: (1670214, 37)\n",
            "Number of rows and columns for bureau: (1716428, 17)\n",
            "Number of rows and columns for previous balance: (27299925, 3)\n",
            "Number of rows and columns for train: (307511, 122)\n",
            "Number of rows and columns for test: (48744, 121)\n"
          ]
        }
      ],
      "source": [
        "#Your code here\n",
        "#The variables that should be implemented to store the data are: app_train, app_test, bureau, app_past\n",
        "\n",
        "\n",
        "# 1 - Loading the different datasets.\n",
        "prev_app = pd.read_csv(previous_application)\n",
        "bureau = pd.read_csv(src_bureau)\n",
        "bureau_balance = pd.read_csv(src_bureau_balance)\n",
        "app_train = pd.read_csv(src_train)\n",
        "app_test = pd.read_csv(src_test)\n",
        "\n",
        "# 2 - The number of rows and columns for each\n",
        "print(f'Number of rows and columns for previous application: {prev_app.shape}')\n",
        "print(f'Number of rows and columns for bureau: {bureau.shape}')\n",
        "print(f'Number of rows and columns for previous balance: {bureau_balance.shape}')\n",
        "print(f'Number of rows and columns for train: {app_train.shape}')\n",
        "print(f'Number of rows and columns for test: {app_test.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnMI0pRmkHzH"
      },
      "source": [
        "<h1> Feature Engineering</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuAAPVW1kH82"
      },
      "source": [
        "<h2>Missing values (9pts)</h2>\n",
        "\n",
        "\n",
        "**3.a**: What columns are missing the most values in app_test?\n",
        "\n",
        "**3.b**: What columns are missing the most values in bureau?\n",
        "\n",
        "**3.c**: What columns are missing the most values in app_past?\n",
        "\n",
        "4: Fix missing data in app_test dataset using categorization and/or simple imputation when appropriate. Be careful to the **data leakage** issue!\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 3: Correct approach + code 2pts.\n",
        "* 4: Description of the approach 4pts. Code implementation of the approach 3pts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GCD-Tet5rKuq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7331c1cd-786e-4721-fbfc-1d4664a36112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with the most missing values: \n",
            "COMMONAREA_AVG              33495\n",
            "COMMONAREA_MODE             33495\n",
            "COMMONAREA_MEDI             33495\n",
            "NONLIVINGAPARTMENTS_AVG     33347\n",
            "NONLIVINGAPARTMENTS_MODE    33347\n",
            "dtype: int64\n",
            "Columns with the most missing values: \n",
            "AMT_ANNUITY               1226791\n",
            "AMT_CREDIT_MAX_OVERDUE    1124488\n",
            "DAYS_ENDDATE_FACT          633653\n",
            "AMT_CREDIT_SUM_LIMIT       591780\n",
            "AMT_CREDIT_SUM_DEBT        257669\n",
            "dtype: int64\n",
            "Columns with the most missing values: \n",
            "RATE_INTEREST_PRIVILEGED    1664263\n",
            "RATE_INTEREST_PRIMARY       1664263\n",
            "AMT_DOWN_PAYMENT             895844\n",
            "RATE_DOWN_PAYMENT            895844\n",
            "NAME_TYPE_SUITE              820405\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 3a missing values on app_test\n",
        "missing_values = app_test.isnull().sum()\n",
        "print(f'Columns with the most missing values: \\n{missing_values.sort_values(ascending=False).head(5)}')\n",
        "\n",
        "# 3b missing values on bureau\n",
        "missing_values = bureau.isnull().sum()\n",
        "print(f'Columns with the most missing values: \\n{missing_values.sort_values(ascending=False).head(5)}')\n",
        "\n",
        "## 3c\n",
        "missing_values =  prev_app.isnull().sum()\n",
        "print(f'Columns with the most missing values: \\n{missing_values.sort_values(ascending=False).head(5)}')\n",
        "\n",
        "# 4: Fix missing data in app_test using categorization and/or simple imputation when appropriate. You should use *only* pandas and numpy here. You should *not* use sklearn (scikit-learn).\n",
        "\n",
        "## Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz6iD4S-rVUy"
      },
      "source": [
        "**4**: Describe your approach, including how you choose the technique to apply, and how you apply the technique (double click to edit a text cell)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRgq0O0R8Dql"
      },
      "source": [
        "## Class Imbalance (8 pts)\n",
        "\n",
        "5. Evaluate the class imbalance of the training set.\n",
        "\n",
        "6. **a** Fix the class imbalance with over/undersampling\n",
        "\n",
        " **b** Use the SMOTE algorithm to fix class imbalance\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 5: Correct approach + code: 2ts\n",
        "* 6.a: code 3pt\n",
        "* 6.b: code 3pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylyaMfXN8Kbd"
      },
      "outputs": [],
      "source": [
        "# 5 - value counts\n",
        "\n",
        "\n",
        "# 5 - histograms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP0jGTbSfQyb"
      },
      "source": [
        "**5**: Describe briefly your observation (double click to edit a text cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTyLbFbxgiD1"
      },
      "outputs": [],
      "source": [
        "# copy your current dataframe with its .copy() method. You should always use the copy() method if you want to keep the original dataframe untouched when you modify\n",
        "# this is a very common bug, so please read  https://www.statology.org/pandas-copy-dataframe/\n",
        "\n",
        "## Your code here\n",
        "app_train_original = ...\n",
        "\n",
        "\n",
        "# 6.a - fix imbalance with undersampling or oversampling\n",
        "# Implement undersampling or oversampling *without* external libraries, only the library provided to implement yourself the chosen solution.\n",
        "\n",
        "## Your code here\n",
        "\n",
        "\n",
        "# 6.b - fix balance with SMOTE on your previously copied dataframe\n",
        "# You can use any external libraries to use SMOTE. We recommend the imbalanced-learn package https://imbalanced-learn.org/stable/over_sampling.html\n",
        "# Make sure to select the appropriate SMOTE variant.\n",
        "\n",
        "\n",
        "## Your code here\n",
        "app_train_smote = ...\n",
        "\n",
        "\n",
        "# We will use the dataframe app_train from 6.a in the following"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27ZdP7aloQb"
      },
      "source": [
        "<h2>Categorical features (9pts)</h2>\n",
        "\n",
        "In `app_test`\n",
        "\n",
        "**7a**: How will you transform the column NAME_HOUSING_TYPE in app_test be correctly handled by the model? How will you transform CODE_GENDER column?\n",
        "\n",
        "**7b**: How would you transform the column NAME_HOUSING_TYPE in app_test if you want only 3 categories? Use LabelEncoder to transform FLAG_OWN_CAR column.\n",
        "\n",
        "**7c**: In ORGANIZATION_TYPE, only keep the categories that appear in more than 10% of the dataset. Group other categories in one. What is the size of the dummy vector for ORGANIZATION_TYPE after this transformation?\n",
        "\n",
        "\n",
        "8: **In app_test, app_past and bureau,** transform all the categorical columns that you have not processed in 7 using One-hot encoding.\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 7: Description of the approach 4pts. Code 3pts.\n",
        "* 8: Correct approach + code 2pts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shlk_faurPh6"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufWJR8ScnHb4"
      },
      "source": [
        "<h2>Anomalies (7 pts)</h2>\n",
        "\n",
        "**In app_test**\n",
        "\n",
        "**9a**: Is there an anomaly with the column DEF_30_CNT_SOCIAL_CIRCLE? If so, how would you solve it?\n",
        "\n",
        "**9b**: Is there an anomaly with the column LANDAREA_AVG? If so, how would you solve it?\n",
        "\n",
        "**9c**: Is there an anomaly with the column AMT_INCOME_TOTAL? If so, how would you solve it?\n",
        "\n",
        "10: Fix the anomaly in DAYS_EMPLOYED?\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 9: Description of the approach + code 5pts.\n",
        "* 10: code 2pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5TcZk8Q5jQ-"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgQ2i5B25lRC"
      },
      "source": [
        "<h2>Correlations (9 pts)</h2>\n",
        "\n",
        "\n",
        "11: **In app_test**, remove the collinear features of the dataset. How did you choose the threshold?\n",
        "\n",
        "12: What features from bureau.csv could you use to improve the training set? Use the random forest model from the notebook of the Lecture to check if it actually improves the final model performance.\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 11: Code 3pts. Threshold explanation 1pt.\n",
        "* 12: Description of the approach 1pt. Code implementation of the approach 2pts. Improved performance 2pts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU1j3LW2S-ir"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_fQJhfcyQWn"
      },
      "source": [
        "##  Class imbalance and model performances (6 points)\n",
        "\n",
        "\n",
        "**13**: Evaluate the other technique (SMOTE) to handeling imbalance data left in *6.b*. Does it makes a difference on the final model performance? Can you use the performance on the test set to choose which techniques to use? If not, what would you need to do so?\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 13: Code 3pts. Explanation 3pts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDR7b8VRyUkS"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kxXg4CA3nPO"
      },
      "source": [
        "**13**: Answer the question here (double click to edit a text cell)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}